{'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', "get_ipython().run_line_magic('load_ext', 'autoreload')\nget_ipython().run_line_magic('matplotlib', 'inline')\nget_ipython().run_line_magic('autoreload', '2')", 'import numpy as np\nimport os\nimport time\nimport h5py\nimport keras\nimport pandas as pd\nimport math\nimport joblib\nimport json\nimport matplotlib.pyplot as plt\n\nfrom fuel.datasets.svhn import SVHN\nfrom IPython.display import display\n\nfrom keras.layers import (Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, \n                          Activation, Dropout, Conv2D, Conv2DTranspose,\n                          Concatenate, Add, Multiply)\nfrom keras.regularizers import l2\nfrom keras.initializers import RandomUniform\nfrom keras.optimizers import RMSprop, Adam, SGD\nfrom keras.models import Model\nfrom keras import metrics\nfrom keras import backend as K\nfrom keras_tqdm import TQDMNotebookCallback\nfrom keras.datasets import mnist\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom resnet import *', "img_rows, img_cols, img_chns = 32, 32, 3\noriginal_img_size = (img_rows, img_cols, img_chns)\nnum_classes = 10\nlearning_rate = float(os.environ.get('LEARNING_RATE', 0.001))\ndecay = float(os.environ.get('DECAY', 0.0))\nbatch_size = int(os.environ.get('BATCH_SIZE', 250))\nepochs = int(os.environ.get('EPOCHS', 100))\nrun_num = int(os.environ.get('RUN_NUM', 0))\nuse_preprocessing = int(os.environ.get('USE_PREPROCESSING', 1))\n\nfile_prefix = 'results_preproc_%d_run_%d_' % (use_preprocessing, run_num)", 'def get_svhn(split):\n    f = SVHN(which_format=2, which_sets=(split,), load_in_memory=True)\n    f.load()\n    X_dataset, y_dataset = f.data_sources\n    \n    X_dataset, y_dataset = np.moveaxis(X_dataset, 1, 3), y_dataset\n    X_dataset = X_dataset / 255.\n    y_dataset = keras.utils.to_categorical(y_dataset, 10)\n    print ("%s - DType X=%s, y=%s" % (split, X_dataset.dtype, y_dataset.dtype))\n    print ("%s - Shape X=%s, y=%s" % (split, X_dataset.shape, y_dataset.shape))\n    \n    return X_dataset, y_dataset\n\n\nX_train_raw, y_train_raw = get_svhn(\'train\')\nvalidation_index = int(len(X_train_raw) * 0.85)\nX_validation, y_validation = X_train_raw[validation_index:], y_train_raw[validation_index:]\nX_train, y_train = X_train_raw[:validation_index], y_train_raw[:validation_index]\nX_test, y_test = get_svhn(\'test\')\n\nprint("raw", len(X_train_raw), len(y_train_raw))\nprint("validation", len(X_validation), len(y_validation))\nprint("train", len(X_train), len(y_train))\nprint("test", len(X_test), len(y_test))', "# Augment data\nif use_preprocessing:\n    datagen = ImageDataGenerator(\n        zoom_range=0.10,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        fill_mode='constant',\n        rotation_range=10)\n    datagen.fit(X_train)\n          \n    X_aug = [X_train]\n    y_aug = [y_train]\n    for i in range(2):\n        X_gen, y_gen = next(datagen.flow(X_train,  y_train, batch_size=len(X_train)))\n        X_aug.append(X_gen)\n        y_aug.append(y_gen)\n        \n    X_train = np.concatenate(tuple(X_aug))\n    y_train = np.concatenate(tuple(y_aug))\n    del X_aug, y_aug, X_gen, y_gen\n    print(X_train.shape, X_train.shape)", "def display_grid(dataset, digit_size=32, grid_size=5, seed=None):\n    # Display some digits to figure out what's going on\n    figure = np.zeros((digit_size * grid_size, digit_size * grid_size, 3))\n   \n    if seed is not None:\n        np.random.seed(seed)\n    for i in range(grid_size):\n        for j in range(grid_size):\n            digit = dataset[np.random.randint(len(dataset))]\n            d_x, d_y = i * digit_size, j * digit_size\n            figure[d_x:d_x + digit_size, d_y:d_y + digit_size, :] = digit.astype(float)\n            \n    plt.figure(figsize=(5, 5))\n    plt.imshow(figure)\n    plt.show()\n\ndisplay_grid(X_train, seed=0)\ndisplay_grid(X_test, seed=0)", "def make_model():\n    x_input = Input(batch_shape=(None,) + original_img_size)\n    resnet_model = ResNet50(weights=None, pooling='avg', input_shape=original_img_size, include_top=False)\n    model_out = resnet_model(x_input)\n    out = Dense(num_classes, activation='softmax', name='fc10')(model_out)\n    model = Model(x_input, out, name='myresent50')\n    return model", 'def train_model(model, y_train_vals):\n    optimizer = Adam(lr=learning_rate, decay=decay)\n    model.compile(optimizer=optimizer,\n                  loss=\'categorical_crossentropy\',\n                  metrics=[\'accuracy\'])\n    \n    start = time.time()\n    \n    early_stopping = keras.callbacks.EarlyStopping(\'val_acc\', min_delta=0.1, patience=20)\n    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\'val_acc\', factor=0.1, patience=10, min_lr=0.01 * learning_rate)\n    \n    callbacks=[early_stopping, reduce_lr]\n    if \'CMDLINE\' not in os.environ:\n        callbacks += [TQDMNotebookCallback()]\n        \n    history = model.fit(\n         X_train, y_train_vals,\n         batch_size=batch_size,\n         epochs=epochs,\n         callbacks=callbacks,\n         validation_data=(X_validation, y_validation),\n         verbose=0\n     )\n    \n    done = time.time()\n    elapsed = done - start\n    print("Elapsed: ", elapsed)\n    \n    return model, history', 'model = make_model()\nmodel.summary()', '# Testing\n# epochs=1\n# model, history = train_model(model, y_train)\n# history.history', 'y_train_predict = y_train\nfor i in range(3):\n    print("Iteration", i)\n    model = make_model()\n    model.summary()\n    model, history = train_model(model, y_train_predict)\n    \n    df = pd.DataFrame(history.history)\n    display(df.describe(percentiles=[0.25 * i for i in range(4)] + [0.95, 0.99]))\n    df.plot(figsize=(8, 6))\n    df.to_csv(file_prefix + (\'history_iter%d\' % i) + \'.csv\', index=False)\n    with open(file_prefix + \'vars.txt\', \'w\') as f:\n        f.write(str(locals()))\n    \n    y_train_predict = model.predict(X_train)\n    y_train_predict\n    \n    test_results = model.evaluate(X_test, y_test)\n    print(test_results)\n    with open(\'allresults.csv\', \'a\') as f:\n        line = \',\'.join([str(use_preprocessing), str(run_num), str(i)] + [str(x) for x in test_results])\n        f.write(line + \'\\n\')'], '_oh': {}, '_dh': ['/home/brian/devel/sandbox/notebooks/label_refinery'], 'In': ['', "get_ipython().run_line_magic('load_ext', 'autoreload')\nget_ipython().run_line_magic('matplotlib', 'inline')\nget_ipython().run_line_magic('autoreload', '2')", 'import numpy as np\nimport os\nimport time\nimport h5py\nimport keras\nimport pandas as pd\nimport math\nimport joblib\nimport json\nimport matplotlib.pyplot as plt\n\nfrom fuel.datasets.svhn import SVHN\nfrom IPython.display import display\n\nfrom keras.layers import (Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, \n                          Activation, Dropout, Conv2D, Conv2DTranspose,\n                          Concatenate, Add, Multiply)\nfrom keras.regularizers import l2\nfrom keras.initializers import RandomUniform\nfrom keras.optimizers import RMSprop, Adam, SGD\nfrom keras.models import Model\nfrom keras import metrics\nfrom keras import backend as K\nfrom keras_tqdm import TQDMNotebookCallback\nfrom keras.datasets import mnist\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom resnet import *', "img_rows, img_cols, img_chns = 32, 32, 3\noriginal_img_size = (img_rows, img_cols, img_chns)\nnum_classes = 10\nlearning_rate = float(os.environ.get('LEARNING_RATE', 0.001))\ndecay = float(os.environ.get('DECAY', 0.0))\nbatch_size = int(os.environ.get('BATCH_SIZE', 250))\nepochs = int(os.environ.get('EPOCHS', 100))\nrun_num = int(os.environ.get('RUN_NUM', 0))\nuse_preprocessing = int(os.environ.get('USE_PREPROCESSING', 1))\n\nfile_prefix = 'results_preproc_%d_run_%d_' % (use_preprocessing, run_num)", 'def get_svhn(split):\n    f = SVHN(which_format=2, which_sets=(split,), load_in_memory=True)\n    f.load()\n    X_dataset, y_dataset = f.data_sources\n    \n    X_dataset, y_dataset = np.moveaxis(X_dataset, 1, 3), y_dataset\n    X_dataset = X_dataset / 255.\n    y_dataset = keras.utils.to_categorical(y_dataset, 10)\n    print ("%s - DType X=%s, y=%s" % (split, X_dataset.dtype, y_dataset.dtype))\n    print ("%s - Shape X=%s, y=%s" % (split, X_dataset.shape, y_dataset.shape))\n    \n    return X_dataset, y_dataset\n\n\nX_train_raw, y_train_raw = get_svhn(\'train\')\nvalidation_index = int(len(X_train_raw) * 0.85)\nX_validation, y_validation = X_train_raw[validation_index:], y_train_raw[validation_index:]\nX_train, y_train = X_train_raw[:validation_index], y_train_raw[:validation_index]\nX_test, y_test = get_svhn(\'test\')\n\nprint("raw", len(X_train_raw), len(y_train_raw))\nprint("validation", len(X_validation), len(y_validation))\nprint("train", len(X_train), len(y_train))\nprint("test", len(X_test), len(y_test))', "# Augment data\nif use_preprocessing:\n    datagen = ImageDataGenerator(\n        zoom_range=0.10,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        fill_mode='constant',\n        rotation_range=10)\n    datagen.fit(X_train)\n          \n    X_aug = [X_train]\n    y_aug = [y_train]\n    for i in range(2):\n        X_gen, y_gen = next(datagen.flow(X_train,  y_train, batch_size=len(X_train)))\n        X_aug.append(X_gen)\n        y_aug.append(y_gen)\n        \n    X_train = np.concatenate(tuple(X_aug))\n    y_train = np.concatenate(tuple(y_aug))\n    del X_aug, y_aug, X_gen, y_gen\n    print(X_train.shape, X_train.shape)", "def display_grid(dataset, digit_size=32, grid_size=5, seed=None):\n    # Display some digits to figure out what's going on\n    figure = np.zeros((digit_size * grid_size, digit_size * grid_size, 3))\n   \n    if seed is not None:\n        np.random.seed(seed)\n    for i in range(grid_size):\n        for j in range(grid_size):\n            digit = dataset[np.random.randint(len(dataset))]\n            d_x, d_y = i * digit_size, j * digit_size\n            figure[d_x:d_x + digit_size, d_y:d_y + digit_size, :] = digit.astype(float)\n            \n    plt.figure(figsize=(5, 5))\n    plt.imshow(figure)\n    plt.show()\n\ndisplay_grid(X_train, seed=0)\ndisplay_grid(X_test, seed=0)", "def make_model():\n    x_input = Input(batch_shape=(None,) + original_img_size)\n    resnet_model = ResNet50(weights=None, pooling='avg', input_shape=original_img_size, include_top=False)\n    model_out = resnet_model(x_input)\n    out = Dense(num_classes, activation='softmax', name='fc10')(model_out)\n    model = Model(x_input, out, name='myresent50')\n    return model", 'def train_model(model, y_train_vals):\n    optimizer = Adam(lr=learning_rate, decay=decay)\n    model.compile(optimizer=optimizer,\n                  loss=\'categorical_crossentropy\',\n                  metrics=[\'accuracy\'])\n    \n    start = time.time()\n    \n    early_stopping = keras.callbacks.EarlyStopping(\'val_acc\', min_delta=0.1, patience=20)\n    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\'val_acc\', factor=0.1, patience=10, min_lr=0.01 * learning_rate)\n    \n    callbacks=[early_stopping, reduce_lr]\n    if \'CMDLINE\' not in os.environ:\n        callbacks += [TQDMNotebookCallback()]\n        \n    history = model.fit(\n         X_train, y_train_vals,\n         batch_size=batch_size,\n         epochs=epochs,\n         callbacks=callbacks,\n         validation_data=(X_validation, y_validation),\n         verbose=0\n     )\n    \n    done = time.time()\n    elapsed = done - start\n    print("Elapsed: ", elapsed)\n    \n    return model, history', 'model = make_model()\nmodel.summary()', '# Testing\n# epochs=1\n# model, history = train_model(model, y_train)\n# history.history', 'y_train_predict = y_train\nfor i in range(3):\n    print("Iteration", i)\n    model = make_model()\n    model.summary()\n    model, history = train_model(model, y_train_predict)\n    \n    df = pd.DataFrame(history.history)\n    display(df.describe(percentiles=[0.25 * i for i in range(4)] + [0.95, 0.99]))\n    df.plot(figsize=(8, 6))\n    df.to_csv(file_prefix + (\'history_iter%d\' % i) + \'.csv\', index=False)\n    with open(file_prefix + \'vars.txt\', \'w\') as f:\n        f.write(str(locals()))\n    \n    y_train_predict = model.predict(X_train)\n    y_train_predict\n    \n    test_results = model.evaluate(X_test, y_test)\n    print(test_results)\n    with open(\'allresults.csv\', \'a\') as f:\n        line = \',\'.join([str(use_preprocessing), str(run_num), str(i)] + [str(x) for x in test_results])\n        f.write(line + \'\\n\')'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f6cbf6d1320>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x7f6cbf69efd0>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x7f6cbf69efd0>, '_': '', '__': '', '___': '', '_i': '# Testing\n# epochs=1\n# model, history = train_model(model, y_train)\n# history.history', '_ii': 'model = make_model()\nmodel.summary()', '_iii': 'def train_model(model, y_train_vals):\n    optimizer = Adam(lr=learning_rate, decay=decay)\n    model.compile(optimizer=optimizer,\n                  loss=\'categorical_crossentropy\',\n                  metrics=[\'accuracy\'])\n    \n    start = time.time()\n    \n    early_stopping = keras.callbacks.EarlyStopping(\'val_acc\', min_delta=0.1, patience=20)\n    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\'val_acc\', factor=0.1, patience=10, min_lr=0.01 * learning_rate)\n    \n    callbacks=[early_stopping, reduce_lr]\n    if \'CMDLINE\' not in os.environ:\n        callbacks += [TQDMNotebookCallback()]\n        \n    history = model.fit(\n         X_train, y_train_vals,\n         batch_size=batch_size,\n         epochs=epochs,\n         callbacks=callbacks,\n         validation_data=(X_validation, y_validation),\n         verbose=0\n     )\n    \n    done = time.time()\n    elapsed = done - start\n    print("Elapsed: ", elapsed)\n    \n    return model, history', '_i1': '%load_ext autoreload\n%matplotlib inline\n%autoreload 2', '_i2': 'import numpy as np\nimport os\nimport time\nimport h5py\nimport keras\nimport pandas as pd\nimport math\nimport joblib\nimport json\nimport matplotlib.pyplot as plt\n\nfrom fuel.datasets.svhn import SVHN\nfrom IPython.display import display\n\nfrom keras.layers import (Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, \n                          Activation, Dropout, Conv2D, Conv2DTranspose,\n                          Concatenate, Add, Multiply)\nfrom keras.regularizers import l2\nfrom keras.initializers import RandomUniform\nfrom keras.optimizers import RMSprop, Adam, SGD\nfrom keras.models import Model\nfrom keras import metrics\nfrom keras import backend as K\nfrom keras_tqdm import TQDMNotebookCallback\nfrom keras.datasets import mnist\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom resnet import *', 'np': <module 'numpy' from '/home/brian/anaconda3/lib/python3.6/site-packages/numpy/__init__.py'>, 'os': <module 'os' from '/home/brian/anaconda3/lib/python3.6/os.py'>, 'time': <module 'time' (built-in)>, 'h5py': <module 'h5py' from '/home/brian/anaconda3/lib/python3.6/site-packages/h5py/__init__.py'>, 'keras': <module 'keras' from '/home/brian/anaconda3/lib/python3.6/site-packages/keras/__init__.py'>, 'pd': <module 'pandas' from '/home/brian/anaconda3/lib/python3.6/site-packages/pandas/__init__.py'>, 'math': <module 'math' from '/home/brian/anaconda3/lib/python3.6/lib-dynload/math.cpython-36m-x86_64-linux-gnu.so'>, 'joblib': <module 'joblib' from '/home/brian/anaconda3/lib/python3.6/site-packages/joblib/__init__.py'>, 'json': <module 'json' from '/home/brian/anaconda3/lib/python3.6/json/__init__.py'>, 'plt': <module 'matplotlib.pyplot' from '/home/brian/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py'>, 'SVHN': <class 'fuel.datasets.svhn.SVHN'>, 'display': <function display at 0x7f6cc4cab268>, 'Input': <function Input at 0x7f6c68679bf8>, 'Dense': <class 'keras.layers.core.Dense'>, 'Lambda': <class 'keras.layers.core.Lambda'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'Reshape': <class 'keras.layers.core.Reshape'>, 'BatchNormalization': <class 'keras.layers.normalization.BatchNormalization'>, 'Activation': <class 'keras.layers.core.Activation'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'Conv2D': <class 'keras.layers.convolutional.Conv2D'>, 'Conv2DTranspose': <class 'keras.layers.convolutional.Conv2DTranspose'>, 'Concatenate': <class 'keras.layers.merge.Concatenate'>, 'Add': <class 'keras.layers.merge.Add'>, 'Multiply': <class 'keras.layers.merge.Multiply'>, 'l2': <function l2 at 0x7f6c5b0e82f0>, 'RandomUniform': <class 'keras.initializers.RandomUniform'>, 'RMSprop': <class 'keras.optimizers.RMSprop'>, 'Adam': <class 'keras.optimizers.Adam'>, 'SGD': <class 'keras.optimizers.SGD'>, 'Model': <class 'keras.engine.training.Model'>, 'metrics': <module 'keras.metrics' from '/home/brian/anaconda3/lib/python3.6/site-packages/keras/metrics.py'>, 'K': <module 'keras.backend' from '/home/brian/anaconda3/lib/python3.6/site-packages/keras/backend/__init__.py'>, 'TQDMNotebookCallback': <class 'keras_tqdm.tqdm_notebook_callback.TQDMNotebookCallback'>, 'mnist': <module 'keras.datasets.mnist' from '/home/brian/anaconda3/lib/python3.6/site-packages/keras/datasets/mnist.py'>, 'ImageDataGenerator': <class 'keras.preprocessing.image.ImageDataGenerator'>, 'absolute_import': _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0), 16384), 'division': _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192), 'print_function': _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 65536), 'warnings': <module 'warnings' from '/home/brian/anaconda3/lib/python3.6/warnings.py'>, 'backend': <module 'keras.backend' from '/home/brian/anaconda3/lib/python3.6/site-packages/keras/backend/__init__.py'>, 'layers': <module 'keras.layers' from '/home/brian/anaconda3/lib/python3.6/site-packages/keras/layers/__init__.py'>, 'models': <module 'keras.models' from '/home/brian/anaconda3/lib/python3.6/site-packages/keras/models.py'>, 'keras_utils': <module 'keras.utils' from '/home/brian/anaconda3/lib/python3.6/site-packages/keras/utils/__init__.py'>, 'imagenet_utils': <module 'imagenet_utils' from '/home/brian/devel/sandbox/notebooks/label_refinery/imagenet_utils.py'>, 'decode_predictions': <function decode_predictions at 0x7f6c54095e18>, 'preprocess_input': <function preprocess_input at 0x7f6c54095d90>, 'WEIGHTS_PATH': 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5', 'WEIGHTS_PATH_NO_TOP': 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', 'identity_block': <function identity_block at 0x7f6c54095950>, 'conv_block': <function conv_block at 0x7f6c54095f28>, 'ResNet50': <function ResNet50 at 0x7f6c5409a048>, '_i3': "img_rows, img_cols, img_chns = 32, 32, 3\noriginal_img_size = (img_rows, img_cols, img_chns)\nnum_classes = 10\nlearning_rate = float(os.environ.get('LEARNING_RATE', 0.001))\ndecay = float(os.environ.get('DECAY', 0.0))\nbatch_size = int(os.environ.get('BATCH_SIZE', 250))\nepochs = int(os.environ.get('EPOCHS', 100))\nrun_num = int(os.environ.get('RUN_NUM', 0))\nuse_preprocessing = int(os.environ.get('USE_PREPROCESSING', 1))\n\nfile_prefix = 'results_preproc_%d_run_%d_' % (use_preprocessing, run_num)", 'img_rows': 32, 'img_cols': 32, 'img_chns': 3, 'original_img_size': (32, 32, 3), 'num_classes': 10, 'learning_rate': 0.001, 'decay': 0.0, 'batch_size': 250, 'epochs': 100, 'run_num': 2, 'use_preprocessing': 0, 'file_prefix': 'results_preproc_0_run_2_', '_i4': 'def get_svhn(split):\n    f = SVHN(which_format=2, which_sets=(split,), load_in_memory=True)\n    f.load()\n    X_dataset, y_dataset = f.data_sources\n    \n    X_dataset, y_dataset = np.moveaxis(X_dataset, 1, 3), y_dataset\n    X_dataset = X_dataset / 255.\n    y_dataset = keras.utils.to_categorical(y_dataset, 10)\n    print ("%s - DType X=%s, y=%s" % (split, X_dataset.dtype, y_dataset.dtype))\n    print ("%s - Shape X=%s, y=%s" % (split, X_dataset.shape, y_dataset.shape))\n    \n    return X_dataset, y_dataset\n\n\nX_train_raw, y_train_raw = get_svhn(\'train\')\nvalidation_index = int(len(X_train_raw) * 0.85)\nX_validation, y_validation = X_train_raw[validation_index:], y_train_raw[validation_index:]\nX_train, y_train = X_train_raw[:validation_index], y_train_raw[:validation_index]\nX_test, y_test = get_svhn(\'test\')\n\nprint("raw", len(X_train_raw), len(y_train_raw))\nprint("validation", len(X_validation), len(y_validation))\nprint("train", len(X_train), len(y_train))\nprint("test", len(X_test), len(y_test))', 'get_svhn': <function get_svhn at 0x7f6cbc0f4b70>, 'X_train_raw': array([[[[0.12941176, 0.11764706, 0.14901961],
         [0.05882353, 0.09019608, 0.0745098 ],
         [0.05882353, 0.06666667, 0.0745098 ],
         ...,
         [0.28235294, 0.25490196, 0.21960784],
         [0.32156863, 0.30196078, 0.22352941],
         [0.34901961, 0.30980392, 0.23137255]],

        [[0.10980392, 0.15294118, 0.1372549 ],
         [0.05490196, 0.09803922, 0.08627451],
         [0.05490196, 0.07843137, 0.06666667],
         ...,
         [0.15686275, 0.15294118, 0.19607843],
         [0.2627451 , 0.22745098, 0.20392157],
         [0.3254902 , 0.30588235, 0.23529412]],

        [[0.15686275, 0.16078431, 0.14901961],
         [0.07058824, 0.08235294, 0.10196078],
         [0.0627451 , 0.06666667, 0.09019608],
         ...,
         [0.09019608, 0.11372549, 0.17647059],
         [0.1372549 , 0.16470588, 0.17254902],
         [0.28235294, 0.27058824, 0.20784314]],

        ...,

        [[0.3372549 , 0.31764706, 0.29411765],
         [0.34117647, 0.32156863, 0.27843137],
         [0.32156863, 0.30980392, 0.25490196],
         ...,
         [0.40784314, 0.40784314, 0.34117647],
         [0.40784314, 0.41176471, 0.31764706],
         [0.40392157, 0.41176471, 0.30588235]],

        [[0.32941176, 0.3372549 , 0.25098039],
         [0.3372549 , 0.30980392, 0.28235294],
         [0.32156863, 0.29803922, 0.28235294],
         ...,
         [0.43137255, 0.40392157, 0.32941176],
         [0.41568627, 0.41176471, 0.33333333],
         [0.41568627, 0.40784314, 0.3372549 ]],

        [[0.33333333, 0.34509804, 0.26666667],
         [0.34901961, 0.32156863, 0.28235294],
         [0.33333333, 0.30980392, 0.2627451 ],
         ...,
         [0.43529412, 0.40784314, 0.34117647],
         [0.42745098, 0.41176471, 0.3372549 ],
         [0.40392157, 0.41568627, 0.30980392]]],


       [[[0.32941176, 0.29803922, 0.23137255],
         [0.3372549 , 0.28627451, 0.25882353],
         [0.30196078, 0.30588235, 0.21960784],
         ...,
         [0.35294118, 0.30588235, 0.27058824],
         [0.34509804, 0.30196078, 0.2627451 ],
         [0.34509804, 0.30588235, 0.25882353]],

        [[0.33333333, 0.30196078, 0.23921569],
         [0.3254902 , 0.28627451, 0.25098039],
         [0.29019608, 0.27058824, 0.23137255],
         ...,
         [0.34901961, 0.32156863, 0.25098039],
         [0.34509804, 0.30980392, 0.2745098 ],
         [0.34509804, 0.31764706, 0.2627451 ]],

        [[0.3254902 , 0.29803922, 0.23529412],
         [0.30588235, 0.30196078, 0.22745098],
         [0.23921569, 0.19607843, 0.21176471],
         ...,
         [0.35294118, 0.33333333, 0.24705882],
         [0.34509804, 0.3254902 , 0.25882353],
         [0.33333333, 0.32156863, 0.2745098 ]],

        ...,

        [[0.39215686, 0.38431373, 0.28235294],
         [0.38431373, 0.36862745, 0.29803922],
         [0.37254902, 0.36470588, 0.28627451],
         ...,
         [0.40784314, 0.40784314, 0.3372549 ],
         [0.4       , 0.4       , 0.34117647],
         [0.39215686, 0.39607843, 0.30588235]],

        [[0.40392157, 0.40784314, 0.30980392],
         [0.41568627, 0.40784314, 0.30980392],
         [0.40392157, 0.40392157, 0.34117647],
         ...,
         [0.40392157, 0.40784314, 0.3372549 ],
         [0.40392157, 0.40392157, 0.34117647],
         [0.41176471, 0.38823529, 0.31764706]],

        [[0.40392157, 0.41568627, 0.32156863],
         [0.40392157, 0.41176471, 0.34117647],
         [0.40784314, 0.41568627, 0.35686275],
         ...,
         [0.44313725, 0.40392157, 0.34509804],
         [0.40784314, 0.40784314, 0.34509804],
         [0.40392157, 0.38431373, 0.31372549]]],


       [[[0.0745098 , 0.21176471, 0.43137255],
         [0.07843137, 0.20392157, 0.43529412],
         [0.09803922, 0.22352941, 0.45490196],
         ...,
         [0.25490196, 0.56470588, 0.8745098 ],
         [0.30588235, 0.58039216, 0.85490196],
         [0.38431373, 0.61960784, 0.8627451 ]],

        [[0.08235294, 0.20784314, 0.43137255],
         [0.0745098 , 0.20392157, 0.41568627],
         [0.09803922, 0.21960784, 0.43529412],
         ...,
         [0.24705882, 0.5372549 , 0.81568627],
         [0.35686275, 0.6       , 0.83921569],
         [0.50980392, 0.70588235, 0.89803922]],

        [[0.08235294, 0.20784314, 0.43137255],
         [0.07843137, 0.2       , 0.41568627],
         [0.08627451, 0.20392157, 0.41568627],
         ...,
         [0.30980392, 0.57647059, 0.82352941],
         [0.49019608, 0.70980392, 0.90196078],
         [0.69803922, 0.85490196, 0.99607843]],

        ...,

        [[0.34509804, 0.63529412, 0.92941176],
         [0.34901961, 0.63921569, 0.93333333],
         [0.32941176, 0.61176471, 0.90196078],
         ...,
         [0.24313725, 0.55686275, 0.89019608],
         [0.2627451 , 0.56470588, 0.88627451],
         [0.29019608, 0.56862745, 0.88235294]],

        [[0.34509804, 0.64313725, 0.94117647],
         [0.34117647, 0.62745098, 0.92941176],
         [0.34509804, 0.62352941, 0.92941176],
         ...,
         [0.23529412, 0.55294118, 0.90196078],
         [0.23921569, 0.55294118, 0.89411765],
         [0.25490196, 0.56078431, 0.88627451]],

        [[0.32941176, 0.62745098, 0.93333333],
         [0.31764706, 0.60392157, 0.91372549],
         [0.34117647, 0.61960784, 0.93333333],
         ...,
         [0.24705882, 0.56470588, 0.92156863],
         [0.24313725, 0.56078431, 0.90980392],
         [0.24705882, 0.56862745, 0.90588235]]],


       ...,


       [[[0.36078431, 0.30588235, 0.39607843],
         [0.36862745, 0.32156863, 0.41176471],
         [0.44705882, 0.39607843, 0.49019608],
         ...,
         [0.78431373, 0.78823529, 0.79607843],
         [0.75294118, 0.75686275, 0.76470588],
         [0.74509804, 0.74901961, 0.75686275]],

        [[0.36078431, 0.30588235, 0.40392157],
         [0.36470588, 0.31372549, 0.41568627],
         [0.43529412, 0.38431373, 0.48627451],
         ...,
         [0.70980392, 0.70588235, 0.72156863],
         [0.69411765, 0.69019608, 0.70588235],
         [0.71764706, 0.71372549, 0.73333333]],

        [[0.38823529, 0.32941176, 0.43921569],
         [0.36862745, 0.31764706, 0.43137255],
         [0.41960784, 0.36862745, 0.48235294],
         ...,
         [0.65490196, 0.65098039, 0.67058824],
         [0.6745098 , 0.67058824, 0.69019608],
         [0.7254902 , 0.72156863, 0.74117647]],

        ...,

        [[0.38823529, 0.36862745, 0.43137255],
         [0.37647059, 0.35686275, 0.42745098],
         [0.42352941, 0.40392157, 0.48627451],
         ...,
         [0.82352941, 0.81176471, 0.8       ],
         [0.80784314, 0.79215686, 0.78431373],
         [0.79607843, 0.77254902, 0.78039216]],

        [[0.36862745, 0.35686275, 0.40392157],
         [0.36862745, 0.35686275, 0.40784314],
         [0.43137255, 0.41960784, 0.4745098 ],
         ...,
         [0.85882353, 0.85490196, 0.84313725],
         [0.85490196, 0.84313725, 0.83137255],
         [0.83137255, 0.81960784, 0.81960784]],

        [[0.34509804, 0.34117647, 0.36862745],
         [0.33333333, 0.32941176, 0.36470588],
         [0.41176471, 0.40392157, 0.44705882],
         ...,
         [0.85098039, 0.85098039, 0.83921569],
         [0.86666667, 0.8627451 , 0.85882353],
         [0.85490196, 0.85098039, 0.85490196]]],


       [[[0.74509804, 0.7372549 , 0.74901961],
         [0.80392157, 0.79607843, 0.80784314],
         [0.8627451 , 0.85490196, 0.8627451 ],
         ...,
         [0.89803922, 0.90588235, 0.87843137],
         [0.89803922, 0.89803922, 0.87843137],
         [0.89803922, 0.89411765, 0.8745098 ]],

        [[0.71764706, 0.71372549, 0.72941176],
         [0.78431373, 0.78039216, 0.78823529],
         [0.85490196, 0.85098039, 0.85490196],
         ...,
         [0.89019608, 0.89411765, 0.8745098 ],
         [0.89019608, 0.88627451, 0.87058824],
         [0.89411765, 0.87843137, 0.86666667]],

        [[0.67058824, 0.66666667, 0.68627451],
         [0.74117647, 0.74117647, 0.75686275],
         [0.83529412, 0.83529412, 0.84313725],
         ...,
         [0.90588235, 0.90196078, 0.88627451],
         [0.89803922, 0.88627451, 0.8745098 ],
         [0.89019608, 0.8745098 , 0.8627451 ]],

        ...,

        [[0.73333333, 0.7254902 , 0.72941176],
         [0.8       , 0.79215686, 0.78039216],
         [0.85098039, 0.85098039, 0.82352941],
         ...,
         [0.8       , 0.78431373, 0.76470588],
         [0.76862745, 0.75686275, 0.74117647],
         [0.76862745, 0.75686275, 0.74117647]],

        [[0.72941176, 0.72156863, 0.7254902 ],
         [0.77647059, 0.77254902, 0.76078431],
         [0.82745098, 0.82745098, 0.8       ],
         ...,
         [0.87058824, 0.84705882, 0.83137255],
         [0.83921569, 0.81960784, 0.80392157],
         [0.81568627, 0.80392157, 0.78431373]],

        [[0.74509804, 0.7372549 , 0.74509804],
         [0.78039216, 0.77254902, 0.76078431],
         [0.81568627, 0.81568627, 0.78823529],
         ...,
         [0.90980392, 0.89019608, 0.8745098 ],
         [0.88627451, 0.86666667, 0.84705882],
         [0.85490196, 0.83529412, 0.81960784]]],


       [[[0.84705882, 0.85098039, 0.83137255],
         [0.86666667, 0.87058824, 0.85098039],
         [0.88627451, 0.89019608, 0.86666667],
         ...,
         [0.78431373, 0.78039216, 0.74901961],
         [0.75686275, 0.7372549 , 0.71372549],
         [0.77254902, 0.74117647, 0.72941176]],

        [[0.8       , 0.80392157, 0.79215686],
         [0.82352941, 0.82745098, 0.81568627],
         [0.8627451 , 0.86666667, 0.85098039],
         ...,
         [0.78823529, 0.78039216, 0.75686275],
         [0.76470588, 0.74901961, 0.72941176],
         [0.76862745, 0.74509804, 0.72941176]],

        [[0.77647059, 0.77647059, 0.77254902],
         [0.79215686, 0.79215686, 0.78823529],
         [0.83137255, 0.82745098, 0.82352941],
         ...,
         [0.79607843, 0.78431373, 0.76862745],
         [0.77647059, 0.76078431, 0.74901961],
         [0.76470588, 0.74509804, 0.73333333]],

        ...,

        [[0.91372549, 0.88627451, 0.89411765],
         [0.90196078, 0.87843137, 0.88235294],
         [0.89411765, 0.8745098 , 0.86666667],
         ...,
         [0.77647059, 0.76862745, 0.74509804],
         [0.72156863, 0.71764706, 0.69411765],
         [0.74117647, 0.73333333, 0.71372549]],

        [[0.90588235, 0.88627451, 0.89411765],
         [0.89803922, 0.87843137, 0.88235294],
         [0.89019608, 0.8745098 , 0.87058824],
         ...,
         [0.76470588, 0.76078431, 0.72941176],
         [0.70980392, 0.70980392, 0.67843137],
         [0.72941176, 0.71764706, 0.69411765]],

        [[0.90196078, 0.88627451, 0.89019608],
         [0.90196078, 0.88627451, 0.89019608],
         [0.89803922, 0.88235294, 0.88627451],
         ...,
         [0.74509804, 0.74509804, 0.70980392],
         [0.69803922, 0.69411765, 0.6627451 ],
         [0.70980392, 0.69803922, 0.67058824]]]]), 'y_train_raw': array([[0., 1., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 1.],
       [0., 0., 1., ..., 0., 0., 0.],
       ...,
       [0., 1., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 1.]]), 'validation_index': 62268, 'X_validation': array([[[[0.2627451 , 0.43137255, 0.35294118],
         [0.25490196, 0.42745098, 0.34509804],
         [0.25098039, 0.42745098, 0.34901961],
         ...,
         [0.26666667, 0.40392157, 0.37254902],
         [0.27058824, 0.41176471, 0.37647059],
         [0.27058824, 0.41568627, 0.37254902]],

        [[0.2627451 , 0.43137255, 0.35686275],
         [0.25490196, 0.42352941, 0.34901961],
         [0.24705882, 0.41960784, 0.34509804],
         ...,
         [0.29019608, 0.40392157, 0.39215686],
         [0.29411765, 0.41568627, 0.39215686],
         [0.27843137, 0.40392157, 0.37647059]],

        [[0.25098039, 0.42352941, 0.35686275],
         [0.25098039, 0.42352941, 0.35686275],
         [0.25882353, 0.42745098, 0.35294118],
         ...,
         [0.49411765, 0.55686275, 0.57254902],
         [0.5372549 , 0.59607843, 0.60784314],
         [0.49411765, 0.56470588, 0.57254902]],

        ...,

        [[0.68627451, 0.71764706, 0.76470588],
         [0.56470588, 0.6       , 0.63921569],
         [0.4       , 0.45098039, 0.49803922],
         ...,
         [0.30980392, 0.43529412, 0.41960784],
         [0.30588235, 0.43137255, 0.41176471],
         [0.28235294, 0.41568627, 0.39215686]],

        [[0.66666667, 0.69411765, 0.74509804],
         [0.55294118, 0.58431373, 0.63921569],
         [0.40784314, 0.44705882, 0.50588235],
         ...,
         [0.28627451, 0.44705882, 0.41176471],
         [0.28627451, 0.44705882, 0.41568627],
         [0.26666667, 0.43529412, 0.4       ]],

        [[0.68235294, 0.70196078, 0.76078431],
         [0.6       , 0.62745098, 0.68235294],
         [0.48627451, 0.52941176, 0.58039216],
         ...,
         [0.26666667, 0.44705882, 0.40392157],
         [0.27058824, 0.45098039, 0.40784314],
         [0.25882353, 0.44705882, 0.4       ]]],


       [[[0.24313725, 0.40784314, 0.32941176],
         [0.23137255, 0.39607843, 0.31764706],
         [0.22352941, 0.38431373, 0.30588235],
         ...,
         [0.25882353, 0.42745098, 0.34901961],
         [0.25490196, 0.43137255, 0.34901961],
         [0.2627451 , 0.42745098, 0.34901961]],

        [[0.23529412, 0.39607843, 0.3254902 ],
         [0.22352941, 0.38431373, 0.31764706],
         [0.20784314, 0.36862745, 0.30196078],
         ...,
         [0.25882353, 0.42745098, 0.34901961],
         [0.25490196, 0.42745098, 0.34901961],
         [0.25882353, 0.42745098, 0.34901961]],

        [[0.23137255, 0.39215686, 0.3372549 ],
         [0.21568627, 0.37647059, 0.32156863],
         [0.20392157, 0.36078431, 0.30980392],
         ...,
         [0.25882353, 0.42745098, 0.34901961],
         [0.2627451 , 0.42745098, 0.35294118],
         [0.2627451 , 0.42745098, 0.34901961]],

        ...,

        [[0.69019608, 0.69411765, 0.77647059],
         [0.64705882, 0.65882353, 0.74117647],
         [0.61176471, 0.63529412, 0.70588235],
         ...,
         [0.2745098 , 0.46666667, 0.38431373],
         [0.2745098 , 0.46666667, 0.38431373],
         [0.2745098 , 0.46666667, 0.38823529]],

        [[0.65098039, 0.6745098 , 0.74509804],
         [0.63529412, 0.65882353, 0.72941176],
         [0.61568627, 0.64705882, 0.70588235],
         ...,
         [0.26666667, 0.46666667, 0.39215686],
         [0.26666667, 0.46666667, 0.39215686],
         [0.26666667, 0.46666667, 0.39215686]],

        [[0.53333333, 0.57647059, 0.62745098],
         [0.53333333, 0.58039216, 0.62352941],
         [0.51372549, 0.56862745, 0.6       ],
         ...,
         [0.2627451 , 0.4627451 , 0.38823529],
         [0.26666667, 0.46666667, 0.39215686],
         [0.26666667, 0.46666667, 0.39607843]]],


       [[[0.57647059, 0.59215686, 0.63921569],
         [0.57647059, 0.59215686, 0.63921569],
         [0.57647059, 0.59215686, 0.63529412],
         ...,
         [0.41960784, 0.38039216, 0.39215686],
         [0.38039216, 0.3372549 , 0.35294118],
         [0.36862745, 0.3254902 , 0.34117647]],

        [[0.57647059, 0.59215686, 0.63921569],
         [0.57647059, 0.59215686, 0.63921569],
         [0.57647059, 0.59215686, 0.63529412],
         ...,
         [0.41960784, 0.38039216, 0.39215686],
         [0.38039216, 0.3372549 , 0.35294118],
         [0.36862745, 0.3254902 , 0.34117647]],

        [[0.57254902, 0.58823529, 0.63529412],
         [0.57254902, 0.58823529, 0.63529412],
         [0.57647059, 0.58823529, 0.63137255],
         ...,
         [0.41960784, 0.38039216, 0.39215686],
         [0.38039216, 0.3372549 , 0.35294118],
         [0.36862745, 0.3254902 , 0.34117647]],

        ...,

        [[0.49411765, 0.50588235, 0.54509804],
         [0.48627451, 0.50196078, 0.54117647],
         [0.4745098 , 0.48627451, 0.52156863],
         ...,
         [0.25490196, 0.20392157, 0.21568627],
         [0.23529412, 0.18039216, 0.19215686],
         [0.22745098, 0.17254902, 0.18431373]],

        [[0.49803922, 0.50980392, 0.54509804],
         [0.49411765, 0.50588235, 0.54117647],
         [0.48235294, 0.49411765, 0.5254902 ],
         ...,
         [0.24705882, 0.2       , 0.20784314],
         [0.22352941, 0.17647059, 0.18431373],
         [0.21568627, 0.16862745, 0.17254902]],

        [[0.49803922, 0.50980392, 0.54509804],
         [0.49411765, 0.50588235, 0.54117647],
         [0.48627451, 0.49411765, 0.5254902 ],
         ...,
         [0.24313725, 0.2       , 0.20392157],
         [0.21960784, 0.17647059, 0.18039216],
         [0.21176471, 0.16862745, 0.16862745]]],


       ...,


       [[[0.36078431, 0.30588235, 0.39607843],
         [0.36862745, 0.32156863, 0.41176471],
         [0.44705882, 0.39607843, 0.49019608],
         ...,
         [0.78431373, 0.78823529, 0.79607843],
         [0.75294118, 0.75686275, 0.76470588],
         [0.74509804, 0.74901961, 0.75686275]],

        [[0.36078431, 0.30588235, 0.40392157],
         [0.36470588, 0.31372549, 0.41568627],
         [0.43529412, 0.38431373, 0.48627451],
         ...,
         [0.70980392, 0.70588235, 0.72156863],
         [0.69411765, 0.69019608, 0.70588235],
         [0.71764706, 0.71372549, 0.73333333]],

        [[0.38823529, 0.32941176, 0.43921569],
         [0.36862745, 0.31764706, 0.43137255],
         [0.41960784, 0.36862745, 0.48235294],
         ...,
         [0.65490196, 0.65098039, 0.67058824],
         [0.6745098 , 0.67058824, 0.69019608],
         [0.7254902 , 0.72156863, 0.74117647]],

        ...,

        [[0.38823529, 0.36862745, 0.43137255],
         [0.37647059, 0.35686275, 0.42745098],
         [0.42352941, 0.40392157, 0.48627451],
         ...,
         [0.82352941, 0.81176471, 0.8       ],
         [0.80784314, 0.79215686, 0.78431373],
         [0.79607843, 0.77254902, 0.78039216]],

        [[0.36862745, 0.35686275, 0.40392157],
         [0.36862745, 0.35686275, 0.40784314],
         [0.43137255, 0.41960784, 0.4745098 ],
         ...,
         [0.85882353, 0.85490196, 0.84313725],
         [0.85490196, 0.84313725, 0.83137255],
         [0.83137255, 0.81960784, 0.81960784]],

        [[0.34509804, 0.34117647, 0.36862745],
         [0.33333333, 0.32941176, 0.36470588],
         [0.41176471, 0.40392157, 0.44705882],
         ...,
         [0.85098039, 0.85098039, 0.83921569],
         [0.86666667, 0.8627451 , 0.85882353],
         [0.85490196, 0.85098039, 0.85490196]]],


       [[[0.74509804, 0.7372549 , 0.74901961],
         [0.80392157, 0.79607843, 0.80784314],
         [0.8627451 , 0.85490196, 0.8627451 ],
         ...,
         [0.89803922, 0.90588235, 0.87843137],
         [0.89803922, 0.89803922, 0.87843137],
         [0.89803922, 0.89411765, 0.8745098 ]],

        [[0.71764706, 0.71372549, 0.72941176],
         [0.78431373, 0.78039216, 0.78823529],
         [0.85490196, 0.85098039, 0.85490196],
         ...,
         [0.89019608, 0.89411765, 0.8745098 ],
         [0.89019608, 0.88627451, 0.87058824],
         [0.89411765, 0.87843137, 0.86666667]],

        [[0.67058824, 0.66666667, 0.68627451],
         [0.74117647, 0.74117647, 0.75686275],
         [0.83529412, 0.83529412, 0.84313725],
         ...,
         [0.90588235, 0.90196078, 0.88627451],
         [0.89803922, 0.88627451, 0.8745098 ],
         [0.89019608, 0.8745098 , 0.8627451 ]],

        ...,

        [[0.73333333, 0.7254902 , 0.72941176],
         [0.8       , 0.79215686, 0.78039216],
         [0.85098039, 0.85098039, 0.82352941],
         ...,
         [0.8       , 0.78431373, 0.76470588],
         [0.76862745, 0.75686275, 0.74117647],
         [0.76862745, 0.75686275, 0.74117647]],

        [[0.72941176, 0.72156863, 0.7254902 ],
         [0.77647059, 0.77254902, 0.76078431],
         [0.82745098, 0.82745098, 0.8       ],
         ...,
         [0.87058824, 0.84705882, 0.83137255],
         [0.83921569, 0.81960784, 0.80392157],
         [0.81568627, 0.80392157, 0.78431373]],

        [[0.74509804, 0.7372549 , 0.74509804],
         [0.78039216, 0.77254902, 0.76078431],
         [0.81568627, 0.81568627, 0.78823529],
         ...,
         [0.90980392, 0.89019608, 0.8745098 ],
         [0.88627451, 0.86666667, 0.84705882],
         [0.85490196, 0.83529412, 0.81960784]]],


       [[[0.84705882, 0.85098039, 0.83137255],
         [0.86666667, 0.87058824, 0.85098039],
         [0.88627451, 0.89019608, 0.86666667],
         ...,
         [0.78431373, 0.78039216, 0.74901961],
         [0.75686275, 0.7372549 , 0.71372549],
         [0.77254902, 0.74117647, 0.72941176]],

        [[0.8       , 0.80392157, 0.79215686],
         [0.82352941, 0.82745098, 0.81568627],
         [0.8627451 , 0.86666667, 0.85098039],
         ...,
         [0.78823529, 0.78039216, 0.75686275],
         [0.76470588, 0.74901961, 0.72941176],
         [0.76862745, 0.74509804, 0.72941176]],

        [[0.77647059, 0.77647059, 0.77254902],
         [0.79215686, 0.79215686, 0.78823529],
         [0.83137255, 0.82745098, 0.82352941],
         ...,
         [0.79607843, 0.78431373, 0.76862745],
         [0.77647059, 0.76078431, 0.74901961],
         [0.76470588, 0.74509804, 0.73333333]],

        ...,

        [[0.91372549, 0.88627451, 0.89411765],
         [0.90196078, 0.87843137, 0.88235294],
         [0.89411765, 0.8745098 , 0.86666667],
         ...,
         [0.77647059, 0.76862745, 0.74509804],
         [0.72156863, 0.71764706, 0.69411765],
         [0.74117647, 0.73333333, 0.71372549]],

        [[0.90588235, 0.88627451, 0.89411765],
         [0.89803922, 0.87843137, 0.88235294],
         [0.89019608, 0.8745098 , 0.87058824],
         ...,
         [0.76470588, 0.76078431, 0.72941176],
         [0.70980392, 0.70980392, 0.67843137],
         [0.72941176, 0.71764706, 0.69411765]],

        [[0.90196078, 0.88627451, 0.89019608],
         [0.90196078, 0.88627451, 0.89019608],
         [0.89803922, 0.88235294, 0.88627451],
         ...,
         [0.74509804, 0.74509804, 0.70980392],
         [0.69803922, 0.69411765, 0.6627451 ],
         [0.70980392, 0.69803922, 0.67058824]]]]), 'y_validation': array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 1., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 1., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 1.]]), 'X_train': array([[[[0.12941176, 0.11764706, 0.14901961],
         [0.05882353, 0.09019608, 0.0745098 ],
         [0.05882353, 0.06666667, 0.0745098 ],
         ...,
         [0.28235294, 0.25490196, 0.21960784],
         [0.32156863, 0.30196078, 0.22352941],
         [0.34901961, 0.30980392, 0.23137255]],

        [[0.10980392, 0.15294118, 0.1372549 ],
         [0.05490196, 0.09803922, 0.08627451],
         [0.05490196, 0.07843137, 0.06666667],
         ...,
         [0.15686275, 0.15294118, 0.19607843],
         [0.2627451 , 0.22745098, 0.20392157],
         [0.3254902 , 0.30588235, 0.23529412]],

        [[0.15686275, 0.16078431, 0.14901961],
         [0.07058824, 0.08235294, 0.10196078],
         [0.0627451 , 0.06666667, 0.09019608],
         ...,
         [0.09019608, 0.11372549, 0.17647059],
         [0.1372549 , 0.16470588, 0.17254902],
         [0.28235294, 0.27058824, 0.20784314]],

        ...,

        [[0.3372549 , 0.31764706, 0.29411765],
         [0.34117647, 0.32156863, 0.27843137],
         [0.32156863, 0.30980392, 0.25490196],
         ...,
         [0.40784314, 0.40784314, 0.34117647],
         [0.40784314, 0.41176471, 0.31764706],
         [0.40392157, 0.41176471, 0.30588235]],

        [[0.32941176, 0.3372549 , 0.25098039],
         [0.3372549 , 0.30980392, 0.28235294],
         [0.32156863, 0.29803922, 0.28235294],
         ...,
         [0.43137255, 0.40392157, 0.32941176],
         [0.41568627, 0.41176471, 0.33333333],
         [0.41568627, 0.40784314, 0.3372549 ]],

        [[0.33333333, 0.34509804, 0.26666667],
         [0.34901961, 0.32156863, 0.28235294],
         [0.33333333, 0.30980392, 0.2627451 ],
         ...,
         [0.43529412, 0.40784314, 0.34117647],
         [0.42745098, 0.41176471, 0.3372549 ],
         [0.40392157, 0.41568627, 0.30980392]]],


       [[[0.32941176, 0.29803922, 0.23137255],
         [0.3372549 , 0.28627451, 0.25882353],
         [0.30196078, 0.30588235, 0.21960784],
         ...,
         [0.35294118, 0.30588235, 0.27058824],
         [0.34509804, 0.30196078, 0.2627451 ],
         [0.34509804, 0.30588235, 0.25882353]],

        [[0.33333333, 0.30196078, 0.23921569],
         [0.3254902 , 0.28627451, 0.25098039],
         [0.29019608, 0.27058824, 0.23137255],
         ...,
         [0.34901961, 0.32156863, 0.25098039],
         [0.34509804, 0.30980392, 0.2745098 ],
         [0.34509804, 0.31764706, 0.2627451 ]],

        [[0.3254902 , 0.29803922, 0.23529412],
         [0.30588235, 0.30196078, 0.22745098],
         [0.23921569, 0.19607843, 0.21176471],
         ...,
         [0.35294118, 0.33333333, 0.24705882],
         [0.34509804, 0.3254902 , 0.25882353],
         [0.33333333, 0.32156863, 0.2745098 ]],

        ...,

        [[0.39215686, 0.38431373, 0.28235294],
         [0.38431373, 0.36862745, 0.29803922],
         [0.37254902, 0.36470588, 0.28627451],
         ...,
         [0.40784314, 0.40784314, 0.3372549 ],
         [0.4       , 0.4       , 0.34117647],
         [0.39215686, 0.39607843, 0.30588235]],

        [[0.40392157, 0.40784314, 0.30980392],
         [0.41568627, 0.40784314, 0.30980392],
         [0.40392157, 0.40392157, 0.34117647],
         ...,
         [0.40392157, 0.40784314, 0.3372549 ],
         [0.40392157, 0.40392157, 0.34117647],
         [0.41176471, 0.38823529, 0.31764706]],

        [[0.40392157, 0.41568627, 0.32156863],
         [0.40392157, 0.41176471, 0.34117647],
         [0.40784314, 0.41568627, 0.35686275],
         ...,
         [0.44313725, 0.40392157, 0.34509804],
         [0.40784314, 0.40784314, 0.34509804],
         [0.40392157, 0.38431373, 0.31372549]]],


       [[[0.0745098 , 0.21176471, 0.43137255],
         [0.07843137, 0.20392157, 0.43529412],
         [0.09803922, 0.22352941, 0.45490196],
         ...,
         [0.25490196, 0.56470588, 0.8745098 ],
         [0.30588235, 0.58039216, 0.85490196],
         [0.38431373, 0.61960784, 0.8627451 ]],

        [[0.08235294, 0.20784314, 0.43137255],
         [0.0745098 , 0.20392157, 0.41568627],
         [0.09803922, 0.21960784, 0.43529412],
         ...,
         [0.24705882, 0.5372549 , 0.81568627],
         [0.35686275, 0.6       , 0.83921569],
         [0.50980392, 0.70588235, 0.89803922]],

        [[0.08235294, 0.20784314, 0.43137255],
         [0.07843137, 0.2       , 0.41568627],
         [0.08627451, 0.20392157, 0.41568627],
         ...,
         [0.30980392, 0.57647059, 0.82352941],
         [0.49019608, 0.70980392, 0.90196078],
         [0.69803922, 0.85490196, 0.99607843]],

        ...,

        [[0.34509804, 0.63529412, 0.92941176],
         [0.34901961, 0.63921569, 0.93333333],
         [0.32941176, 0.61176471, 0.90196078],
         ...,
         [0.24313725, 0.55686275, 0.89019608],
         [0.2627451 , 0.56470588, 0.88627451],
         [0.29019608, 0.56862745, 0.88235294]],

        [[0.34509804, 0.64313725, 0.94117647],
         [0.34117647, 0.62745098, 0.92941176],
         [0.34509804, 0.62352941, 0.92941176],
         ...,
         [0.23529412, 0.55294118, 0.90196078],
         [0.23921569, 0.55294118, 0.89411765],
         [0.25490196, 0.56078431, 0.88627451]],

        [[0.32941176, 0.62745098, 0.93333333],
         [0.31764706, 0.60392157, 0.91372549],
         [0.34117647, 0.61960784, 0.93333333],
         ...,
         [0.24705882, 0.56470588, 0.92156863],
         [0.24313725, 0.56078431, 0.90980392],
         [0.24705882, 0.56862745, 0.90588235]]],


       ...,


       [[[0.58431373, 0.65882353, 0.63921569],
         [0.60784314, 0.67843137, 0.66666667],
         [0.60784314, 0.66666667, 0.66666667],
         ...,
         [0.61568627, 0.64313725, 0.65490196],
         [0.5254902 , 0.54117647, 0.56862745],
         [0.35294118, 0.35294118, 0.40392157]],

        [[0.61568627, 0.68235294, 0.67058824],
         [0.62352941, 0.69411765, 0.67843137],
         [0.62745098, 0.67843137, 0.67843137],
         ...,
         [0.61176471, 0.65098039, 0.65490196],
         [0.54901961, 0.57254902, 0.59607843],
         [0.38431373, 0.39607843, 0.43921569]],

        [[0.62745098, 0.68627451, 0.69019608],
         [0.62352941, 0.67843137, 0.68235294],
         [0.59215686, 0.63529412, 0.64705882],
         ...,
         [0.61960784, 0.65882353, 0.6627451 ],
         [0.56078431, 0.59215686, 0.61176471],
         [0.4       , 0.41568627, 0.45098039]],

        ...,

        [[0.28627451, 0.33333333, 0.40392157],
         [0.3254902 , 0.37254902, 0.44313725],
         [0.39215686, 0.43137255, 0.49803922],
         ...,
         [0.6       , 0.65098039, 0.63921569],
         [0.57647059, 0.61568627, 0.61568627],
         [0.4745098 , 0.49411765, 0.50588235]],

        [[0.35686275, 0.41568627, 0.47843137],
         [0.39607843, 0.45098039, 0.50980392],
         [0.4627451 , 0.51372549, 0.57254902],
         ...,
         [0.62745098, 0.67843137, 0.66666667],
         [0.60392157, 0.64705882, 0.64313725],
         [0.50588235, 0.53333333, 0.5372549 ]],

        [[0.48627451, 0.55294118, 0.60392157],
         [0.51372549, 0.57647059, 0.62745098],
         [0.54509804, 0.59215686, 0.64705882],
         ...,
         [0.63529412, 0.68627451, 0.6745098 ],
         [0.61176471, 0.65490196, 0.65098039],
         [0.51372549, 0.54901961, 0.54509804]]],


       [[[0.60784314, 0.6745098 , 0.70196078],
         [0.63921569, 0.69803922, 0.72941176],
         [0.63921569, 0.69411765, 0.74117647],
         ...,
         [0.60392157, 0.6627451 , 0.69411765],
         [0.60784314, 0.65882353, 0.6627451 ],
         [0.58823529, 0.60392157, 0.61176471]],

        [[0.60392157, 0.68235294, 0.70588235],
         [0.63137255, 0.69803922, 0.73333333],
         [0.64313725, 0.70588235, 0.76470588],
         ...,
         [0.59607843, 0.69411765, 0.70588235],
         [0.61176471, 0.68235294, 0.67843137],
         [0.60784314, 0.62352941, 0.63137255]],

        [[0.61176471, 0.68627451, 0.71372549],
         [0.63137255, 0.69803922, 0.7372549 ],
         [0.64705882, 0.71372549, 0.76862745],
         ...,
         [0.58039216, 0.69803922, 0.71764706],
         [0.6       , 0.6745098 , 0.69019608],
         [0.6       , 0.61176471, 0.63529412]],

        ...,

        [[0.43529412, 0.46666667, 0.5372549 ],
         [0.49803922, 0.51764706, 0.56470588],
         [0.56862745, 0.57254902, 0.61176471],
         ...,
         [0.58039216, 0.59607843, 0.62352941],
         [0.56470588, 0.6       , 0.60392157],
         [0.54117647, 0.59215686, 0.58431373]],

        [[0.41176471, 0.44705882, 0.50980392],
         [0.48627451, 0.51764706, 0.54901961],
         [0.54509804, 0.56862745, 0.58823529],
         ...,
         [0.56862745, 0.60392157, 0.61176471],
         [0.55294118, 0.59607843, 0.58431373],
         [0.5254902 , 0.57647059, 0.55686275]],

        [[0.37254902, 0.41568627, 0.46666667],
         [0.45098039, 0.49411765, 0.50980392],
         [0.49803922, 0.53333333, 0.54117647],
         ...,
         [0.56078431, 0.60392157, 0.61960784],
         [0.55686275, 0.6       , 0.59215686],
         [0.5372549 , 0.58431373, 0.56470588]]],


       [[[0.2627451 , 0.45098039, 0.36862745],
         [0.2627451 , 0.45098039, 0.36470588],
         [0.2627451 , 0.45098039, 0.36470588],
         ...,
         [0.27058824, 0.40392157, 0.38431373],
         [0.27058824, 0.38823529, 0.37647059],
         [0.2745098 , 0.38039216, 0.37647059]],

        [[0.2745098 , 0.45490196, 0.36862745],
         [0.2745098 , 0.45490196, 0.36470588],
         [0.2745098 , 0.45490196, 0.36470588],
         ...,
         [0.29803922, 0.40784314, 0.4       ],
         [0.32156863, 0.40784314, 0.41960784],
         [0.3372549 , 0.41176471, 0.43137255]],

        [[0.27843137, 0.45490196, 0.36470588],
         [0.27843137, 0.45490196, 0.36470588],
         [0.27843137, 0.45490196, 0.36470588],
         ...,
         [0.39215686, 0.46666667, 0.48235294],
         [0.43921569, 0.49019608, 0.52156863],
         [0.4627451 , 0.50980392, 0.54509804]],

        ...,

        [[0.2627451 , 0.45882353, 0.37647059],
         [0.2627451 , 0.45882353, 0.37254902],
         [0.25490196, 0.45882353, 0.36862745],
         ...,
         [0.31764706, 0.45098039, 0.43529412],
         [0.3254902 , 0.44705882, 0.42745098],
         [0.3254902 , 0.44313725, 0.42352941]],

        [[0.25882353, 0.4627451 , 0.37647059],
         [0.25490196, 0.4627451 , 0.37254902],
         [0.24705882, 0.45882353, 0.36470588],
         ...,
         [0.29411765, 0.45882353, 0.41568627],
         [0.29019608, 0.44313725, 0.40392157],
         [0.29411765, 0.44313725, 0.39607843]],

        [[0.25098039, 0.4627451 , 0.37254902],
         [0.24705882, 0.4627451 , 0.36862745],
         [0.24313725, 0.45882353, 0.36078431],
         ...,
         [0.28235294, 0.47058824, 0.40784314],
         [0.28627451, 0.46666667, 0.40392157],
         [0.29411765, 0.45882353, 0.39607843]]]]), 'y_train': array([[0., 1., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 1.],
       [0., 0., 1., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]]), 'X_test': array([[[[0.14901961, 0.40392157, 0.23529412],
         [0.15294118, 0.40784314, 0.23921569],
         [0.15294118, 0.40784314, 0.24313725],
         ...,
         [0.16078431, 0.4       , 0.23921569],
         [0.16470588, 0.40392157, 0.24313725],
         [0.15294118, 0.38039216, 0.22352941]],

        [[0.15294118, 0.40784314, 0.23921569],
         [0.15294118, 0.40784314, 0.23921569],
         [0.15294118, 0.40784314, 0.24313725],
         ...,
         [0.16078431, 0.4       , 0.23921569],
         [0.16862745, 0.39607843, 0.24705882],
         [0.15294118, 0.38039216, 0.22352941]],

        [[0.14901961, 0.41176471, 0.24313725],
         [0.14509804, 0.40784314, 0.23921569],
         [0.15294118, 0.41568627, 0.24705882],
         ...,
         [0.16862745, 0.39607843, 0.24705882],
         [0.16862745, 0.39215686, 0.25098039],
         [0.15294118, 0.38039216, 0.23137255]],

        ...,

        [[0.20392157, 0.46666667, 0.30588235],
         [0.20784314, 0.47058824, 0.30980392],
         [0.2       , 0.4627451 , 0.30196078],
         ...,
         [0.17254902, 0.4627451 , 0.27058824],
         [0.17254902, 0.45882353, 0.27843137],
         [0.16078431, 0.44705882, 0.27058824]],

        [[0.19607843, 0.45882353, 0.29803922],
         [0.2       , 0.4627451 , 0.30196078],
         [0.19215686, 0.45490196, 0.29411765],
         ...,
         [0.17254902, 0.45882353, 0.27843137],
         [0.17647059, 0.45490196, 0.28235294],
         [0.16470588, 0.44313725, 0.27058824]],

        [[0.18823529, 0.45098039, 0.29019608],
         [0.18823529, 0.45098039, 0.29019608],
         [0.18039216, 0.44313725, 0.28235294],
         ...,
         [0.16862745, 0.45490196, 0.27843137],
         [0.17254902, 0.45098039, 0.27843137],
         [0.16470588, 0.44313725, 0.27843137]]],


       [[[0.50588235, 0.55686275, 0.6       ],
         [0.49803922, 0.56078431, 0.59607843],
         [0.49019608, 0.56078431, 0.59215686],
         ...,
         [0.4745098 , 0.52156863, 0.6       ],
         [0.48235294, 0.5254902 , 0.61176471],
         [0.48235294, 0.52941176, 0.61568627]],

        [[0.5254902 , 0.58823529, 0.62745098],
         [0.52156863, 0.58431373, 0.61960784],
         [0.51764706, 0.58431373, 0.61568627],
         ...,
         [0.49803922, 0.54117647, 0.61568627],
         [0.49411765, 0.5372549 , 0.61568627],
         [0.49019608, 0.5372549 , 0.61960784]],

        [[0.55294118, 0.61960784, 0.65882353],
         [0.54901961, 0.61568627, 0.65098039],
         [0.54901961, 0.61568627, 0.64705882],
         ...,
         [0.52941176, 0.57647059, 0.63921569],
         [0.51764706, 0.56078431, 0.63137255],
         [0.50980392, 0.55294118, 0.62745098]],

        ...,

        [[0.57647059, 0.63137255, 0.68235294],
         [0.55686275, 0.61176471, 0.6627451 ],
         [0.53333333, 0.59215686, 0.63921569],
         ...,
         [0.36470588, 0.38039216, 0.49411765],
         [0.37647059, 0.39215686, 0.50196078],
         [0.40784314, 0.42745098, 0.53333333]],

        [[0.54117647, 0.59607843, 0.64705882],
         [0.50980392, 0.56470588, 0.61568627],
         [0.4745098 , 0.53333333, 0.58039216],
         ...,
         [0.36470588, 0.38823529, 0.50196078],
         [0.39607843, 0.41960784, 0.5254902 ],
         [0.43921569, 0.4627451 , 0.56470588]],

        [[0.51372549, 0.56862745, 0.61960784],
         [0.47843137, 0.53333333, 0.58431373],
         [0.43529412, 0.49411765, 0.54509804],
         ...,
         [0.39607843, 0.42352941, 0.52941176],
         [0.43529412, 0.4627451 , 0.56470588],
         [0.48235294, 0.50980392, 0.61176471]]],


       [[[0.58823529, 0.62745098, 0.6627451 ],
         [0.58823529, 0.63921569, 0.66666667],
         [0.59607843, 0.65882353, 0.6745098 ],
         ...,
         [0.6       , 0.6745098 , 0.70588235],
         [0.58823529, 0.67058824, 0.70980392],
         [0.57647059, 0.6627451 , 0.70588235]],

        [[0.58823529, 0.62745098, 0.6627451 ],
         [0.59215686, 0.63921569, 0.6627451 ],
         [0.6       , 0.65882353, 0.67058824],
         ...,
         [0.61176471, 0.68235294, 0.70588235],
         [0.6       , 0.67058824, 0.70588235],
         [0.58823529, 0.6627451 , 0.70196078]],

        [[0.56470588, 0.60392157, 0.63921569],
         [0.57254902, 0.61568627, 0.63921569],
         [0.58039216, 0.63529412, 0.64705882],
         ...,
         [0.61568627, 0.6745098 , 0.69411765],
         [0.6       , 0.65882353, 0.68627451],
         [0.58823529, 0.64705882, 0.67843137]],

        ...,

        [[0.52941176, 0.58823529, 0.65490196],
         [0.5254902 , 0.58431373, 0.65098039],
         [0.51764706, 0.57647059, 0.64705882],
         ...,
         [0.48627451, 0.54901961, 0.61568627],
         [0.47843137, 0.54509804, 0.61568627],
         [0.4745098 , 0.54117647, 0.61960784]],

        [[0.57647059, 0.64705882, 0.70196078],
         [0.57647059, 0.64313725, 0.70196078],
         [0.57647059, 0.64313725, 0.70196078],
         ...,
         [0.54509804, 0.60784314, 0.66666667],
         [0.54509804, 0.60784314, 0.66666667],
         [0.54117647, 0.60784314, 0.67058824]],

        [[0.62352941, 0.69411765, 0.74117647],
         [0.62352941, 0.69411765, 0.74509804],
         [0.62352941, 0.69411765, 0.74901961],
         ...,
         [0.59607843, 0.65882353, 0.70980392],
         [0.59607843, 0.65882353, 0.71372549],
         [0.59607843, 0.65882353, 0.71764706]]],


       ...,


       [[[0.45098039, 0.51764706, 0.55686275],
         [0.45490196, 0.52156863, 0.56078431],
         [0.45882353, 0.5254902 , 0.56470588],
         ...,
         [0.44705882, 0.53333333, 0.55294118],
         [0.44705882, 0.53333333, 0.55686275],
         [0.45098039, 0.53333333, 0.56078431]],

        [[0.47843137, 0.54509804, 0.58039216],
         [0.48235294, 0.54901961, 0.58431373],
         [0.48627451, 0.55294118, 0.58823529],
         ...,
         [0.4627451 , 0.54509804, 0.56078431],
         [0.4627451 , 0.54509804, 0.56862745],
         [0.46666667, 0.54509804, 0.57254902]],

        [[0.51372549, 0.58039216, 0.60784314],
         [0.51764706, 0.58431373, 0.61176471],
         [0.52156863, 0.58431373, 0.61568627],
         ...,
         [0.49019608, 0.56078431, 0.57647059],
         [0.49019608, 0.56078431, 0.58431373],
         [0.49411765, 0.56470588, 0.58823529]],

        ...,

        [[0.36862745, 0.38039216, 0.44705882],
         [0.36470588, 0.37647059, 0.44313725],
         [0.36078431, 0.37254902, 0.43921569],
         ...,
         [0.54901961, 0.6       , 0.63529412],
         [0.55686275, 0.60784314, 0.64313725],
         [0.56470588, 0.61568627, 0.64705882]],

        [[0.45882353, 0.47843137, 0.5372549 ],
         [0.45882353, 0.47843137, 0.5372549 ],
         [0.4627451 , 0.48235294, 0.5372549 ],
         ...,
         [0.55294118, 0.60392157, 0.63921569],
         [0.56078431, 0.61176471, 0.64313725],
         [0.56470588, 0.61568627, 0.64705882]],

        [[0.51764706, 0.54117647, 0.59607843],
         [0.52156863, 0.54901961, 0.59607843],
         [0.52941176, 0.55686275, 0.6       ],
         ...,
         [0.55686275, 0.60784314, 0.64313725],
         [0.56078431, 0.61176471, 0.64705882],
         [0.56470588, 0.61568627, 0.64705882]]],


       [[[0.37647059, 0.25490196, 0.18431373],
         [0.38039216, 0.25490196, 0.19215686],
         [0.38039216, 0.25490196, 0.19607843],
         ...,
         [0.3372549 , 0.23921569, 0.21176471],
         [0.34117647, 0.24313725, 0.21568627],
         [0.34509804, 0.24705882, 0.21960784]],

        [[0.37647059, 0.25490196, 0.18823529],
         [0.38039216, 0.25490196, 0.19607843],
         [0.38039216, 0.25490196, 0.2       ],
         ...,
         [0.33333333, 0.24313725, 0.20784314],
         [0.34117647, 0.24705882, 0.21176471],
         [0.34509804, 0.25098039, 0.21568627]],

        [[0.37647059, 0.25098039, 0.19215686],
         [0.37647059, 0.25098039, 0.19607843],
         [0.37647059, 0.25098039, 0.2       ],
         ...,
         [0.34117647, 0.25882353, 0.21176471],
         [0.35294118, 0.26666667, 0.22352941],
         [0.35686275, 0.27058824, 0.22745098]],

        ...,

        [[0.38823529, 0.26666667, 0.18823529],
         [0.38823529, 0.2745098 , 0.19607843],
         [0.39215686, 0.28627451, 0.20784314],
         ...,
         [0.54117647, 0.4745098 , 0.41176471],
         [0.49803922, 0.42745098, 0.36470588],
         [0.45882353, 0.38431373, 0.3254902 ]],

        [[0.38431373, 0.2627451 , 0.18039216],
         [0.38823529, 0.2745098 , 0.18823529],
         [0.39215686, 0.28627451, 0.2       ],
         ...,
         [0.49411765, 0.42352941, 0.36078431],
         [0.4627451 , 0.38823529, 0.3254902 ],
         [0.43137255, 0.35686275, 0.29411765]],

        [[0.38039216, 0.25882353, 0.17647059],
         [0.38823529, 0.27058824, 0.18823529],
         [0.39215686, 0.28235294, 0.2       ],
         ...,
         [0.4627451 , 0.38823529, 0.32156863],
         [0.43529412, 0.36078431, 0.29019608],
         [0.40784314, 0.33333333, 0.26666667]]],


       [[[0.39607843, 0.29411765, 0.23529412],
         [0.39215686, 0.28627451, 0.23529412],
         [0.38823529, 0.27843137, 0.23137255],
         ...,
         [0.37254902, 0.24705882, 0.20392157],
         [0.37254902, 0.24705882, 0.20392157],
         [0.37647059, 0.25098039, 0.2       ]],

        [[0.42745098, 0.32941176, 0.27058824],
         [0.41960784, 0.31372549, 0.2627451 ],
         [0.40784314, 0.29803922, 0.25098039],
         ...,
         [0.37254902, 0.24313725, 0.20784314],
         [0.36470588, 0.23921569, 0.19607843],
         [0.36470588, 0.23921569, 0.19215686]],

        [[0.45882353, 0.37254902, 0.30588235],
         [0.44705882, 0.35294118, 0.29411765],
         [0.42352941, 0.3254902 , 0.2745098 ],
         ...,
         [0.37254902, 0.24313725, 0.20784314],
         [0.36078431, 0.23529412, 0.19607843],
         [0.35686275, 0.23137255, 0.18823529]],

        ...,

        [[0.45490196, 0.37647059, 0.33333333],
         [0.45490196, 0.37647059, 0.34117647],
         [0.45098039, 0.37254902, 0.34117647],
         ...,
         [0.39607843, 0.2745098 , 0.19607843],
         [0.39607843, 0.2745098 , 0.19607843],
         [0.39607843, 0.2745098 , 0.19607843]],

        [[0.40784314, 0.3254902 , 0.27843137],
         [0.41176471, 0.32941176, 0.28627451],
         [0.41176471, 0.32941176, 0.29019608],
         ...,
         [0.39607843, 0.2745098 , 0.19215686],
         [0.4       , 0.27843137, 0.19607843],
         [0.4       , 0.27843137, 0.19607843]],

        [[0.37254902, 0.28627451, 0.24313725],
         [0.37647059, 0.29019608, 0.24705882],
         [0.38039216, 0.29411765, 0.25098039],
         ...,
         [0.39607843, 0.2745098 , 0.19215686],
         [0.4       , 0.27843137, 0.19607843],
         [0.4       , 0.27843137, 0.19607843]]]]), 'y_test': array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 1., ..., 0., 0., 0.],
       [0., 1., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 1., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 1., 0., 0.]]), '_i5': "# Augment data\nif use_preprocessing:\n    datagen = ImageDataGenerator(\n        zoom_range=0.10,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        fill_mode='constant',\n        rotation_range=10)\n    datagen.fit(X_train)\n          \n    X_aug = [X_train]\n    y_aug = [y_train]\n    for i in range(2):\n        X_gen, y_gen = next(datagen.flow(X_train,  y_train, batch_size=len(X_train)))\n        X_aug.append(X_gen)\n        y_aug.append(y_gen)\n        \n    X_train = np.concatenate(tuple(X_aug))\n    y_train = np.concatenate(tuple(y_aug))\n    del X_aug, y_aug, X_gen, y_gen\n    print(X_train.shape, X_train.shape)", '_i6': "def display_grid(dataset, digit_size=32, grid_size=5, seed=None):\n    # Display some digits to figure out what's going on\n    figure = np.zeros((digit_size * grid_size, digit_size * grid_size, 3))\n   \n    if seed is not None:\n        np.random.seed(seed)\n    for i in range(grid_size):\n        for j in range(grid_size):\n            digit = dataset[np.random.randint(len(dataset))]\n            d_x, d_y = i * digit_size, j * digit_size\n            figure[d_x:d_x + digit_size, d_y:d_y + digit_size, :] = digit.astype(float)\n            \n    plt.figure(figsize=(5, 5))\n    plt.imshow(figure)\n    plt.show()\n\ndisplay_grid(X_train, seed=0)\ndisplay_grid(X_test, seed=0)", 'display_grid': <function display_grid at 0x7f6c5409a1e0>, '_i7': "def make_model():\n    x_input = Input(batch_shape=(None,) + original_img_size)\n    resnet_model = ResNet50(weights=None, pooling='avg', input_shape=original_img_size, include_top=False)\n    model_out = resnet_model(x_input)\n    out = Dense(num_classes, activation='softmax', name='fc10')(model_out)\n    model = Model(x_input, out, name='myresent50')\n    return model", 'make_model': <function make_model at 0x7f6c540b78c8>, '_i8': 'def train_model(model, y_train_vals):\n    optimizer = Adam(lr=learning_rate, decay=decay)\n    model.compile(optimizer=optimizer,\n                  loss=\'categorical_crossentropy\',\n                  metrics=[\'accuracy\'])\n    \n    start = time.time()\n    \n    early_stopping = keras.callbacks.EarlyStopping(\'val_acc\', min_delta=0.1, patience=20)\n    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\'val_acc\', factor=0.1, patience=10, min_lr=0.01 * learning_rate)\n    \n    callbacks=[early_stopping, reduce_lr]\n    if \'CMDLINE\' not in os.environ:\n        callbacks += [TQDMNotebookCallback()]\n        \n    history = model.fit(\n         X_train, y_train_vals,\n         batch_size=batch_size,\n         epochs=epochs,\n         callbacks=callbacks,\n         validation_data=(X_validation, y_validation),\n         verbose=0\n     )\n    \n    done = time.time()\n    elapsed = done - start\n    print("Elapsed: ", elapsed)\n    \n    return model, history', 'train_model': <function train_model at 0x7f6c4fa9d7b8>, '_i9': 'model = make_model()\nmodel.summary()', 'model': <keras.engine.training.Model object at 0x7f6b1926e780>, '_i10': '# Testing\n# epochs=1\n# model, history = train_model(model, y_train)\n# history.history', '_i11': 'y_train_predict = y_train\nfor i in range(3):\n    print("Iteration", i)\n    model = make_model()\n    model.summary()\n    model, history = train_model(model, y_train_predict)\n    \n    df = pd.DataFrame(history.history)\n    display(df.describe(percentiles=[0.25 * i for i in range(4)] + [0.95, 0.99]))\n    df.plot(figsize=(8, 6))\n    df.to_csv(file_prefix + (\'history_iter%d\' % i) + \'.csv\', index=False)\n    with open(file_prefix + \'vars.txt\', \'w\') as f:\n        f.write(str(locals()))\n    \n    y_train_predict = model.predict(X_train)\n    y_train_predict\n    \n    test_results = model.evaluate(X_test, y_test)\n    print(test_results)\n    with open(\'allresults.csv\', \'a\') as f:\n        line = \',\'.join([str(use_preprocessing), str(run_num), str(i)] + [str(x) for x in test_results])\n        f.write(line + \'\\n\')', 'y_train_predict': array([[6.93681577e-05, 9.95677412e-01, 1.03878137e-03, ...,
        6.32255164e-04, 2.28722361e-04, 3.51632261e-05],
       [1.19232736e-05, 9.44315161e-07, 5.06959987e-06, ...,
        5.80934341e-08, 7.48862612e-06, 9.99948263e-01],
       [1.38581963e-04, 4.63030388e-04, 9.97765064e-01, ...,
        1.16237876e-04, 1.82686126e-05, 8.00117596e-06],
       ...,
       [6.31373898e-10, 3.66018668e-07, 7.87533793e-07, ...,
        2.32614340e-07, 1.30784542e-07, 3.35163895e-06],
       [2.56835647e-05, 2.50311041e-05, 4.18807685e-05, ...,
        1.02860315e-06, 4.90358565e-04, 3.69304553e-06],
       [1.78948594e-05, 2.13003106e-04, 1.30394939e-04, ...,
        2.71018271e-05, 2.35643583e-05, 1.98477297e-04]], dtype=float32), 'i': 2, 'history': <keras.callbacks.History object at 0x7f6b17aa0d68>, 'df':     val_loss   val_acc      loss       acc      lr
0   1.849392  0.428428  1.732878  0.449509  0.0010
1   3.273122  0.314314  1.176404  0.658878  0.0010
2   3.737159  0.270270  0.909511  0.746852  0.0010
3   1.609750  0.557376  0.872306  0.751076  0.0010
4   0.776882  0.756029  0.728596  0.791354  0.0010
5   0.574608  0.823915  0.587835  0.838087  0.0010
6   0.584074  0.816362  0.493049  0.868697  0.0010
7   0.558464  0.824734  0.454007  0.885270  0.0010
8   0.568564  0.826736  0.434993  0.894039  0.0010
9   0.586371  0.817727  0.401406  0.906902  0.0010
10  0.532374  0.841114  0.380250  0.916137  0.0010
11  0.499305  0.845573  0.362415  0.923588  0.0010
12  0.515422  0.847757  0.347443  0.930269  0.0010
13  0.595759  0.821458  0.338290  0.935617  0.0010
14  0.722960  0.784785  0.345900  0.932405  0.0010
15  1.072398  0.704341  0.338486  0.936067  0.0010
16  0.523937  0.843298  0.525634  0.857648  0.0010
17  0.454306  0.862317  0.404263  0.902743  0.0010
18  0.444947  0.864319  0.361404  0.921420  0.0010
19  0.498152  0.853308  0.373603  0.917582  0.0010
20  0.697393  0.780872  0.344606  0.931731  0.0010
21  0.524695  0.840932  0.498322  0.866914  0.0010
22  0.479436  0.852489  0.376643  0.916008  0.0010
23  0.435849  0.869324  0.340412  0.930510  0.0010
24  0.490374  0.857676  0.330159  0.938444  0.0010
25  0.396811  0.886341  0.309013  0.948545  0.0010
26  0.442209  0.868687  0.297937  0.953909  0.0010
27  0.497940  0.849486  0.293623  0.958181  0.0010
28  0.482615  0.860952  0.296522  0.955065  0.0010
29  0.419121  0.875330  0.311075  0.947421  0.0010
30  0.490399  0.851397  0.290783  0.959080  0.0010
31  0.517673  0.842752  0.288184  0.960445  0.0010
32  0.491156  0.853672  0.283827  0.961907  0.0010
33  0.438384  0.872054  0.288331  0.960509  0.0010
34  0.415164  0.879789  0.288482  0.958904  0.0010
35  0.531083  0.840295  0.297946  0.954182  0.0010
36  0.699654  0.790882  0.315548  0.945205  0.0010
37  0.411773  0.876695  0.275892  0.968395  0.0001
38  0.410301  0.877241  0.264632  0.974803  0.0001, 'f': <_io.TextIOWrapper name='results_preproc_0_run_2_vars.txt' mode='w' encoding='UTF-8'>, 'test_results': [0.5721037267617419, 0.8413106945298094], 'line': '0,2,1,0.5721037267617419,0.8413106945298094'}