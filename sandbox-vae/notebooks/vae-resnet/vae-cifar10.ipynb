{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import keras\n",
    "import pandas as pd\n",
    "import math\n",
    "import joblib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fuel.datasets.hdf5 import H5PYDataset\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from IPython.display import display\n",
    "\n",
    "from keras.layers import (Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, \n",
    "                          Activation, Dropout, Conv2D, Conv2DTranspose,\n",
    "                          Concatenate, Add, Multiply)\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from resnet import identity_block, conv_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols, img_chns = 32, 32, 3\n",
    "original_img_size = (img_rows, img_cols, img_chns)\n",
    "\n",
    "batch_size = int(os.environ.get('BATCH_SIZE', 25))\n",
    "latent_dim = int(os.environ.get('LATENT_DIM', 256))\n",
    "intermediate_dim = int(os.environ.get('INTERMEDIATE_DIM', 1024))\n",
    "epsilon_std = 1.0\n",
    "epochs = int(os.environ.get('EPOCHS', 1000))\n",
    "activation = os.environ.get('ACTIVATION', 'sigmoid')\n",
    "dropout = float(os.environ.get('DROPOUT', 0.0))\n",
    "decay = float(os.environ.get('DECAY', 0.0))\n",
    "learning_rate = float(os.environ.get('LEARNING_RATE', 0.001))\n",
    "resnet_depth = int(os.environ.get('RESNET_DEPTH', 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ftrain = H5PYDataset(\"../../data/cifar10/cifar10.hdf5\", which_sets=('train',))\n",
    "X_train, y_train = ftrain.get_data(ftrain.open(), slice(0, ftrain.num_examples))\n",
    "X_train = np.moveaxis(X_train[:], 1, 3)\n",
    "X_train = X_train / 255.\n",
    "\n",
    "ftest = H5PYDataset(\"../../data/cifar10/cifar10.hdf5\", which_sets=('test',))\n",
    "X_test, y_test = ftest.get_data(ftest.open(), slice(0, ftest.num_examples))\n",
    "X_test = np.moveaxis(X_test[:], 1, 3)\n",
    "X_test = X_test / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dense_layers(stage, width):\n",
    "    dense_name = '_'.join(['enc_conv', str(stage)])\n",
    "    bn_name = '_'.join(['enc_bn', str(stage)])\n",
    "    layers = [\n",
    "        Dense(width, name=dense_name),\n",
    "        BatchNormalization(name=bn_name),\n",
    "        Activation(activation),\n",
    "        Dropout(dropout),\n",
    "    ]\n",
    "    return layers\n",
    "\n",
    "def inst_layers(layers, in_layer):\n",
    "    x = in_layer\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, list):\n",
    "            x = inst_layers(layer, x)\n",
    "        else:\n",
    "            x = layer(x)\n",
    "        \n",
    "    return x\n",
    "\n",
    "def sampling(args, batch_size=batch_size, latent_dim=latent_dim, epsilon_std=epsilon_std):\n",
    "    z_mean, z_log_var = args\n",
    "    \n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    \n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "\n",
    "def resnet_layers(x, depth, stage_base, transpose=False):\n",
    "    assert depth in [0, 1, 2, 3]\n",
    "    \n",
    "    filters = [64, 64, 256]\n",
    "    x = conv_block(x, 3, filters, stage=stage_base + 2, block='a', strides=(1, 1), transpose=transpose)\n",
    "    if depth >= 2:\n",
    "        x = identity_block(x, 3, filters, stage=stage_base + 2, block='b')\n",
    "    if depth >= 3:\n",
    "        x = identity_block(x, 3, filters, stage=stage_base + 2, block='c')\n",
    "   \n",
    "    filters = [128, 128, 512]\n",
    "    x = conv_block(x, 3, filters, stage=stage_base + 3, block='a', transpose=transpose)\n",
    "    if depth >= 1:\n",
    "        x = identity_block(x, 3, filters, stage=stage_base + 3, block='b')\n",
    "    if depth >= 2:\n",
    "        x = identity_block(x, 3, filters, stage=stage_base + 3, block='c')\n",
    "    if depth >= 3:\n",
    "        x = identity_block(x, 3, filters, stage=stage_base + 3, block='d')\n",
    "    \n",
    "    filters = [256, 256, 1024]\n",
    "    x = conv_block(x, 3, filters, stage=stage_base + 4, block='a', transpose=transpose)\n",
    "    if depth >= 1:\n",
    "        x = identity_block(x, 3, filters, stage=stage_base + 4, block='b')\n",
    "    if depth >= 2:\n",
    "        x = identity_block(x, 3, filters, stage=stage_base + 4, block='c')\n",
    "        x = identity_block(x, 3, filters, stage=stage_base + 4, block='d')\n",
    "    if depth >= 3:\n",
    "        x = identity_block(x, 3, filters, stage=stage_base + 4, block='e')\n",
    "        x = identity_block(x, 3, filters, stage=stage_base + 4, block='f')\n",
    "   \n",
    "    filters =  [512, 512, 2048]\n",
    "    x = conv_block(x, 3, filters, stage=stage_base + 5, block='a', transpose=transpose)\n",
    "    if depth >= 2:\n",
    "        x = identity_block(x, 3, filters, stage=stage_base + 5, block='b')\n",
    "    if depth >= 3:\n",
    "        x = identity_block(x, 3, filters, stage=stage_base + 5, block='c')\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def kl_loss(x, x_decoded_mean):\n",
    "    kl_loss = - 0.5 * K.sum(1. + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "   \n",
    "    return K.mean(kl_loss)\n",
    "\n",
    "def logx_loss(x, x_decoded_mean):\n",
    "    x = K.flatten(x)\n",
    "    x_decoded_mean = K.flatten(x_decoded_mean)\n",
    "    xent_loss = img_rows * img_cols * img_chns * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "    return xent_loss\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    return logx_loss(x, x_decoded_mean) + kl_loss(x, x_decoded_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_encoder():\n",
    "    encoder_input = Input(batch_shape=(batch_size,) + original_img_size)\n",
    "    resnet = resnet_layers(encoder_input, depth=resnet_depth, stage_base=0)\n",
    "    encoder_layers = [\n",
    "        create_dense_layers(stage=9, width=intermediate_dim),\n",
    "        Flatten(),\n",
    "    ]\n",
    "    enc_dense = inst_layers(encoder_layers, resnet)\n",
    "    \n",
    "    z_mean = Dense(latent_dim, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(enc_dense)\n",
    "    z_log_var = Dense(latent_dim, kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1))(enc_dense)\n",
    "    \n",
    "    return Model(inputs=encoder_input, outputs=[z_mean, z_log_var])\n",
    "\n",
    "def make_decoder():\n",
    "    decoder_input = Input(batch_shape=(batch_size,) + (latent_dim,))\n",
    "    decoder_layers = [\n",
    "        create_dense_layers(stage=10, width=intermediate_dim),\n",
    "        Reshape((4, 4, intermediate_dim // 16)),\n",
    "    ]\n",
    "    dec_out = inst_layers(decoder_layers, decoder_input)\n",
    "    \n",
    "    dec_out = resnet_layers(dec_out, depth=resnet_depth, transpose=True, stage_base=10)\n",
    "    decoder_out = Conv2DTranspose(name='x_decoded', filters=3, kernel_size=1, strides=1, activation='sigmoid')(dec_out)\n",
    "    \n",
    "    return Model(inputs=decoder_input, outputs=decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = make_encoder()\n",
    "decoder = make_decoder()\n",
    "\n",
    "encoder.summary()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VAE\n",
    "x_input = Input(batch_shape=(batch_size,) + original_img_size)\n",
    "z_mean, z_log_var = encoder(x_input)\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "_output = decoder(z)\n",
    "\n",
    "vae = Model(inputs=x_input, outputs=_output)\n",
    "optimizer = Adam(lr=learning_rate, decay=decay)\n",
    "vae.compile(optimizer=optimizer, loss=vae_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping('val_loss', min_delta=0.1, patience=50)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=0.001 * learning_rate)\n",
    "callbacks=[early_stopping, reduce_lr]\n",
    "if 'CMDLINE' not in os.environ:\n",
    "    callbacks += [TQDMNotebookCallback()]\n",
    "\n",
    "history = vae.fit(\n",
    "    X_train, X_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_test, X_test),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "done = time.time()\n",
    "elapsed = done - start\n",
    "print(\"Elapsed: \", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "display(df.describe(percentiles=[0.25 * i for i in range(4)] + [0.95, 0.99]))\n",
    "df.plot(figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Eval kl loss\n",
    "m = Model(inputs=x_input, outputs=_output)\n",
    "optimizer = Adam(lr=learning_rate, decay=decay)\n",
    "m.compile(optimizer=optimizer, loss=kl_loss)\n",
    "val_kl_loss = m.evaluate(x=X_test, y=X_test, batch_size=batch_size)\n",
    "\n",
    "# Eval logx loss\n",
    "m = Model(inputs=x_input, outputs=_output)\n",
    "optimizer = Adam(lr=learning_rate, decay=decay)\n",
    "m.compile(optimizer=optimizer, loss=logx_loss)\n",
    "val_logx_loss = m.evaluate(x=X_test, y=X_test, batch_size=batch_size)\n",
    "\n",
    "print()\n",
    "print(\"kl_loss = %.2f\" % val_kl_loss)\n",
    "print(\"logx_loss = %.2f\" % val_logx_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "figure = np.zeros((img_rows * n, img_cols * n, img_chns))\n",
    "\n",
    "batches = (n * n + batch_size - 1) // batch_size\n",
    "digits = []\n",
    "for i in range(batches):\n",
    "    z_sample = np.random.normal(size=[batch_size, latent_dim]).reshape(batch_size, latent_dim)\n",
    "    x_decoded = decoder.predict(z_sample, batch_size=batch_size)\n",
    "    digits += [x_decoded[i].reshape(img_rows, img_cols, img_chns) for i in range(batch_size)]\n",
    "\n",
    "for j in range(n):\n",
    "    for i in range(n):\n",
    "        digit = digits[j * n + i]\n",
    "        d_x = i * img_rows\n",
    "        d_y = j * img_cols\n",
    "        figure[d_x:d_x + img_rows, d_y:d_y + img_cols] = digit\n",
    "        \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.environ.get('OUTDIR', None):\n",
    "    encoder.save(os.path.join(os.environ['OUTDIR'], 'encoder-depth-' + str(resnet_depth) + '.h5'))\n",
    "    decoder.save(os.path.join(os.environ['OUTDIR'], 'decoder-depth-' + str(resnet_depth) + '.h5'))\n",
    "\n",
    "    vals = {k: v for k, v in locals().items() if type(v) in [int, float, bool]}\n",
    "    with open(os.path.join(os.environ['OUTDIR'], 'params-depth-' + str(resnet_depth) + '.json'), 'w') as f:\n",
    "        json.dump(vals, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
